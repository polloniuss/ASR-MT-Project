{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6dae9e4-4c19-44f3-aa25-14732df8033e",
   "metadata": {},
   "source": [
    "This notebook is written for transformers==**4.23.1**, torch==**1.12.1+cu102**, and torchaudio==**0.12.1+cu102**; update your packages if needed.\n",
    "\n",
    "[ASR Inference with CTC Decoder](https://pytorch.org/audio/main/tutorials/asr_inference_with_ctc_decoder_tutorial.html#acoustic-model-and-set-up)<br>\n",
    "[Source Code for audiotorch.pipelines._wav2vec2.impl](https://pytorch.org/audio/stable/_modules/torchaudio/pipelines/_wav2vec2/impl.html#Wav2Vec2ASRBundle)<br>\n",
    "[CTC Beam Search Decoder -- The Definition of the Decoder Class](https://pytorch.org/audio/stable/models.decoder.html#ctcdecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405b92f2-ae8e-486e-bc6a-edb5c94ba3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torchaudio/_internal/module_utils.py:99: UserWarning: Failed to import soundfile. 'soundfile' backend is not available.\n",
      "  warnings.warn(\"Failed to import soundfile. 'soundfile' backend is not available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "from torchaudio.models.decoder import ctc_decoder\n",
    "from torchaudio.models.wav2vec2.utils import import_huggingface_model\n",
    "from transformers import Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3ea1bc-e604-4599-9a18-f257f13a65e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n",
      "0.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea74f7-122e-4d17-89d7-1d672bf6dfc9",
   "metadata": {},
   "source": [
    "### **Data**\n",
    "\n",
    "For this experiment, we'll use 4 audio files from the Common Voice 8.0 that were previously transcribed with mistakes (by several model setups) and several completely new audio files selected randomly from the Common Voice 11.0 that weren't previously seen by the model (4 of which can be categorized as pertaining to the medical sphere). (The audio files should be placed in the same directory as this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2621df4b-37f4-4418-bb11-3b14345f3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = [# old files from Common Voice 8.0\n",
    "             \"common_voice_uk_21581951.wav\",\n",
    "             \"common_voice_uk_21619415.wav\",\n",
    "             \"common_voice_uk_27603609.wav\",\n",
    "             \"common_voice_uk_27934776.wav\",\n",
    "             # new files from Common Voice 11.0\n",
    "             \"common_voice_uk_21565096.wav\",\n",
    "             \"common_voice_uk_21565097.wav\",\n",
    "             \"common_voice_uk_21585010.wav\",\n",
    "             \"common_voice_uk_25154983.wav\",\n",
    "             \"common_voice_uk_25154984.wav\",\n",
    "             \"common_voice_uk_25155499.wav\",\n",
    "             \"common_voice_uk_25652074.wav\",\n",
    "             \"common_voice_uk_25652099.wav\",\n",
    "             \"common_voice_uk_27278380.wav\",\n",
    "             \"common_voice_uk_27278438.wav\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3abd2-0242-40f2-bbda-7134ea4c8a75",
   "metadata": {},
   "source": [
    "### **Inference with `transformers`**\n",
    "Instantiate the model and its processor. The processor is composed of 3 integral components:\n",
    "-  feature_extractor (processes speech signal to the model's input format)\n",
    "-  tokenizer (processes the model's output format to text)\n",
    "-  CTC decoder (with the Language Model (LM) support for the improved speech recognition decoding)\n",
    "You can check the processor's components a bit more thoroughly and access, for instance, the tokenizer's vocabulary -- a set of possible predictions, which, in case of the ASR model, is an alphabet and some extra symbols. Next, you can see that the processor is instantiated with the default, fallback CTC decoder and the language model (LM) created from the dataset used for the model's training.<br>\n",
    "\n",
    "(All 3 components can be instantiated separately and then passed to the processor as its parameters but, as you've already confirmed for yourself, there's no need in that because these components and their paramaters are automatically added and fully setup within the processor.)<br>\n",
    "```python\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2CTCTokenizer\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"Yehor/wav2vec2-xls-r-300m-uk-with-small-lm\")\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"Yehor/wav2vec2-xls-r-300m-uk-with-small-lm\")\n",
    "decoder = build_ctcdecoder(...)\n",
    "\n",
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(feature_extractor=feature_extractor, tokenizer=tokenizer, decoder=decoder)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b2892c-e193-446c-b001-7201f7a12067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'snapshot_download': allow_regex. Will not be supported from version '0.12'.\n",
      "\n",
      "Please use `allow_patterns` and `ignore_patterns` instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd4668ed21f494daeefb840696073ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/studio-lab-user/.cache/pyctcdecode/models--Yehor--wav2vec2-xls-r-300m-uk-with-small-lm/snapshots/bbd936400e7566ba44560440aa4abd05b5983c17/language_model/5gram_correct.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"Wav2Vec2ProcessorWithLM\",\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "PreTrainedTokenizer(name_or_path='Yehor/wav2vec2-xls-r-300m-uk-with-small-lm', vocab_size=38, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]', 'additional_special_tokens': [AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True)]})\n",
      "<pyctcdecode.decoder.BeamSearchDecoderCTC object at 0x7f3ff3790f70>\n",
      "<pyctcdecode.language_model.LanguageModel object at 0x7f3ff3790790>\n",
      "[\"'\", '-', '[PAD]', '[UNK]', '|', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ь', 'ю', 'я', 'є', 'і', 'ї', 'ґ', '<s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "model1 = Wav2Vec2ForCTC.from_pretrained(\"Yehor/wav2vec2-xls-r-300m-uk-with-small-lm\")\n",
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(\"Yehor/wav2vec2-xls-r-300m-uk-with-small-lm\")\n",
    "\n",
    "print(processor.feature_extractor)\n",
    "print(processor.tokenizer)\n",
    "print(processor.decoder)\n",
    "print(processor.language_model)\n",
    "\n",
    "# Extract the labels (the model's alphabet) from the tokenizer\n",
    "labels = list(processor.tokenizer.get_vocab().keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da6042-9c87-4e4e-b080-47d512e6f24c",
   "metadata": {},
   "source": [
    "### **Experiment**\n",
    "\n",
    "First, let's define a function for the greedy search algorithm, also known as **best-path decoding**.<br>\n",
    "Next, let's set `beam_width=200`, and run the inference again. The default value for this parameter in the `pyctcdecode` decoder is 100. (**OBS!** The experiment has also been conducted for the `beam_width` of 1500, but there were no significant improvements in the transcription quality gained due to the beam saturation. In general, usually running your inference with the beams wider than 100-200 isn't recommended because that would cause a considerable decoding speed decrease.) You can also check the ASR model's predicted score and the LM's predicted score for each transcription as follows:\n",
    "```python\n",
    "print(processor.decode(outputs, beam_width=200).logit_score)\n",
    "print(processor.decode(outputs, beam_width=200).lm_score)\n",
    "```\n",
    "Finally, let's check if attaching a custom LM affects the generated sentences in any major way. To initialize the CTC beam search decoder with a custom LM, you'll need:<br>\n",
    "-  to generate a vocabulary file from the `unigrams.txt` file, which will trigger the lexicon-constrained beam search decoding (i.e. we'll instruct the model to reduce the search space down to the vocabulary, so that only words existing in it can be predicted)<br>\n",
    "-  to create / or take a ready KenLM file (either `.arpa` or `.bin` one; the latter is recommended for faster loading).\n",
    "\n",
    "The extra parameters, such as the alpha and beta weights, are usually tuned on a validation dataset. The alpha parameter is a weight for the LM; the beta is used to adjust the length score. **Additionally, you can view all the generated transcriptions for each audio file as follows**:\n",
    "```python\n",
    "print(lm_decoder.decode_beams(outputs))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf020f6-3852-4a40-930b-f58ba65927b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(logits):\n",
    "    \"\"\"Decode argmax of logits and squash in CTC fashion.\"\"\"\n",
    "    # Revert the dictionary that maps from letters and symbols\n",
    "    # (labels) to indices, to map from indices to labels\n",
    "    label_dict = {n: c for n, c in enumerate(labels)}\n",
    "    prev_c = None\n",
    "    out = []\n",
    "    for n in logits.argmax(axis=1):\n",
    "        # If not in labels, then assume it's a CTC blank character\n",
    "        c = label_dict.get(n, \"\")\n",
    "        if c != prev_c and c != \"[PAD]\":\n",
    "            out.append(c)\n",
    "        prev_c = c\n",
    "    return \"\".join(out).replace(\"|\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d0f9c7-0dd7-49d3-ac9c-38052681704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the greedy search decoding.\n",
      "про це повідомляє през служба поліції київської області\n",
      "зібрані дані застосовувалися поперше для гернерування адресної розсилки\n",
      "хто розлягається огокворогого котрого втемрі віно не помітили \n",
      "буває професійні помічники домовляються з домовласником напавно ціну за квартиру \n",
      "перестаралося з корекцію вилиць \n",
      "про це свічить її зваложена й доглянута шкіра \n",
      "сім'ї зінвалідами іншим пільговиками постійно потребуватимуть комплексної державної підтримки\n",
      "антибіотикорезистентний\n",
      "антианемічний\n",
      "до переваг цього методу належить простотатехнологічних схем і можливість творення замкнутих циклів\n",
      "еч сіймач фегра і захистив титул\n",
      "зверніть увагу жодної державністі московської не пахне\n",
      "між частинами озброєним рушницями виблискували на сонці косарі і відділи озброєні косами \n",
      "рельєв хрепта сильно розчавлений вусчьовій зоні вирівнюється до переферій за рахунок поховання осить \n"
     ]
    }
   ],
   "source": [
    "# GREEDY SEARCH DECODING\n",
    "print(\"Test the greedy search decoding.\")\n",
    "transcriptions_greedy = []\n",
    "for wav_file in wav_files:\n",
    "    waveform, sample_rate = torchaudio.load(wav_file)\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000, resampling_method='sinc_interpolation')\n",
    "    speech_array = resampler(waveform).squeeze().numpy()\n",
    "    inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\")['input_values']\n",
    "    # Squeeze the batch_size dimension: [1, 149, 40] -> [149, 40],\n",
    "    # to get the distribution of the labels for the entire sequence\n",
    "    outputs = model1(inputs)['logits'].detach().numpy().squeeze(0)\n",
    "    sequence = greedy_decode(outputs)\n",
    "    transcriptions_greedy.append(sequence)\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4665e8-6ddc-4448-a927-01dea798614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test the beam search decoding. (Default LM)\n",
      "про це повідомляє пре служба поліції київської області\n",
      "зібрані дані застосовувалися по перше для гернерування адресної розсилки\n",
      "хто розлягається гокворогого котрого в темряві у не помітили\n",
      "буває професійні помічники домовляються з домовласником напавно ціну за квартиру\n",
      "перестаралася з корекцією вилиць\n",
      "про це свідчить її зволожена й доглянута шкіра\n",
      "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки\n",
      "антибіотикорезистентний\n",
      "антианемічний\n",
      "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів\n",
      "едж свій мачфегра і захистив титул\n",
      "зверніть увагу жодної державністі московською не пахне\n",
      "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами\n",
      "рельєф хребта сильно розчавлений в осьовій зоні вирівнюється до переферій за рахунок поховання осить\n"
     ]
    }
   ],
   "source": [
    "# BEAM SEARCH DECODING\n",
    "print(\"\\nTest the beam search decoding. (Default LM)\")\n",
    "transcriptions_beam_defaultlm = []\n",
    "for wav_file in wav_files:\n",
    "    waveform, sample_rate = torchaudio.load(wav_file)\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000, resampling_method='sinc_interpolation')\n",
    "    speech_array = resampler(waveform).squeeze().numpy()\n",
    "    inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\")['input_values']\n",
    "    # Squeeze the batch_size dimension: [1, 149, 40] -> [149, 40],\n",
    "    # to get the distribution of the labels for the entire sequence\n",
    "    outputs = model1(inputs)['logits'].detach().numpy().squeeze(0)\n",
    "    sequence = processor.decode(outputs, beam_width=200).text\n",
    "    transcriptions_beam_defaultlm.append(sequence)\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19df9439-5466-43ed-97cd-e2bf4e6d9e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/studio-lab-user/sagemaker-studiolab-notebooks/asr_experiments/5gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyctcdecode.decoder.BeamSearchDecoderCTC object at 0x7f3ffda72280>\n",
      "<pyctcdecode.decoder.BeamSearchDecoderCTC object at 0x7f3ff3790f70>\n"
     ]
    }
   ],
   "source": [
    "# Generate a vocab file from `unigrams.txt`\n",
    "with open(\"unigrams.txt\", mode='r', encoding='utf-8') as f:\n",
    "    vocab_list = [t.lower() for t in f.read().strip().split('\\n')]\n",
    "    \n",
    "lm_decoder = build_ctcdecoder(\n",
    "    labels = labels,\n",
    "    kenlm_model_path = '5gram.arpa',\n",
    "    unigrams = vocab_list,\n",
    "    # LM weight\n",
    "    alpha = 0.5,\n",
    "    # LM usage reward (never set to 0)\n",
    "    beta = 2.0,\n",
    "    # unk_score_offset=-10.0,\n",
    "    # lm_score_boundary=True,\n",
    ")\n",
    "\n",
    "# Sanity check: we're using two different CTC decoders and, hence,\n",
    "# two different language models\n",
    "print(lm_decoder)\n",
    "print(processor.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99070e58-c72b-42a1-a1e7-9b796a0e3954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test the beam search decoding. (Custom LM)\n",
      "про це повідомляє пре служба поліції київської області\n",
      "зібрані дані застосовувалися по перше для гернерування адресної розсилки\n",
      "хто розлягається гокворогого котрого в темряві у не помітили\n",
      "буває професійні помічники домовляються з домовласником напавно ціну за квартиру\n",
      "перестаралася з корекцією вилиць\n",
      "про це свідчить її зволожена й доглянута шкіра\n",
      "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки\n",
      "антибіотикорезистентний\n",
      "антианемічний\n",
      "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів\n",
      "едж свій меч фегра і захистив титул\n",
      "зверніть увагу жодної державністі московською не пахне\n",
      "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами\n",
      "рельєф хребта сильно розчавлений в осьовій зоні вирівнюється до переферій за рахунок поховання осить\n"
     ]
    }
   ],
   "source": [
    "# BEAM SEARCH WITH CUSTOM LANGUAGE MODEL\n",
    "print(\"\\nTest the beam search decoding. (Custom LM)\")\n",
    "transcriptions_beam_customlm = []\n",
    "for wav_file in wav_files:\n",
    "    waveform, sample_rate = torchaudio.load(wav_file)\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000, resampling_method='sinc_interpolation')\n",
    "    speech_array = resampler(waveform).squeeze().numpy()\n",
    "    inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\")['input_values']\n",
    "    # Squeeze the batch_size dimension: [1, 149, 40] -> [149, 40],\n",
    "    # to get the distribution of the labels for the entire sequence\n",
    "    outputs = model1(inputs)['logits'].detach().numpy().squeeze(0)\n",
    "    sequence = lm_decoder.decode(outputs)\n",
    "    transcriptions_beam_customlm.append(sequence)\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d7964-7ab5-45ef-b211-67bc54e4824e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Eror Analysis**\n",
    "**OBS!** For each audio file, Line 1 -- greedy search, Line 2 -- beam search (default LM), Line 3 -- beam search (custom LM). Mistakes are marked in **bold**.\n",
    "\n",
    "про це повідомляє пре**з** служба поліції київської області<br>\n",
    "про це повідомляє **пре** служба поліції київської області<br>\n",
    "про це повідомляє **пре** служба поліції київської області<br>\n",
    "The beam search decoding didn't fix the greedy-search mistake, but only introduced a new one to replace it.<br>\n",
    "\n",
    "зібрані дані застосовувалися **поперше** для ге**р**нерування адресної розсилки<br>\n",
    "зібрані дані застосовувалися **по перше** для ге**р**нерування адресної розсилки<br>\n",
    "зібрані дані застосовувалися **по перше** для ге**р**нерування адресної розсилки<br>\n",
    "Here, the beam search didn't correct the spelling of the first word entirely, but it's closer to the proper spelling because it should be hyphened. This can be fixed by creating a new LM with the hyphened words -- it seems that right now the LM lexicon file misses such information.<br>\n",
    "\n",
    "хто розлягається **огокворогого** котрого **втемрі** **віно** не помітили<br>\n",
    "хто розлягається **гокворогого** котрого в темряві **у** не помітили<br>\n",
    "хто розлягається **гокворогого** котрого в темряві **у** не помітили<br>\n",
    "While two mistakes weren't corrected, there is a small improvement for the second mistake with the beam search.<br>\n",
    "\n",
    "буває професійні помічники домовляються з домовласником **напавно** ціну за квартиру<br>\n",
    "буває професійні помічники домовляються з домовласником **напавно** ціну за квартиру<br>\n",
    "буває професійні помічники домовляються з домовласником **напавно** ціну за квартиру<br>\n",
    "No improvements from the beam search on this transcription.<br>\n",
    "\n",
    "перестарал**о**ся з корекцію вилиць<br>\n",
    "перестаралася з корекцією вилиць<br>\n",
    "перестаралася з корекцією вилиць<br>\n",
    "The mistake (wrong gender-specific ending of the verb) is corrected by the beam search.<br>\n",
    "\n",
    "про це **свічить** її зв**а**ложена й доглянута шкіра<br>\n",
    "про це свідчить її зволожена й доглянута шкіра<br>\n",
    "про це свідчить її зволожена й доглянута шкіра<br>\n",
    "Both mistakes are corrected by the beam search.<br>\n",
    "\n",
    "сім'ї **зінвалідами** **іншим** пільговиками постійно потребуватимуть комплексної державної підтримки<br>\n",
    "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки<br>\n",
    "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки<br>\n",
    "Both mistakes are corrected by the beam search. However, it seems that all three transcripts miss the conjunction 'й' (and) between the words 3 and 4.<br>\n",
    "\n",
    "антибіотикорезистентний<br>\n",
    "антибіотикорезистентний<br>\n",
    "антибіотикорезистентний<br>\n",
    "No mistakes were made by any of the decoding methods.<br>\n",
    "\n",
    "антианемічний<br>\n",
    "антианемічний<br>\n",
    "антианемічний<br>\n",
    "No mistakes were made by any of the decoding methods.<br>\n",
    "\n",
    "до переваг цього методу належить **простотатехнологічних** схем і можливість **творення** замкнутих циклів<br>\n",
    "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів<br>\n",
    "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів<br>\n",
    "Both mistakes are corrected by the beam search.<br>\n",
    "\n",
    "**еч** **сіймач** **фегра** і захистив титул<br>\n",
    "едж свій **мачфегра** і захистив титул<br>\n",
    "едж свій **меч фегра** і захистив титул<br>\n",
    "While the most important error wasn't fixed by the beam search (there's no such words as 'фегра' / 'мачфегра', and the audio should have been transcribed as 'матч виграв' (won the match)), it still managed to at least get the first two words right.<br>\n",
    "\n",
    "зверніть увагу жодн**ої** державніст**і** московськ**ої** не пахне<br>\n",
    "зверніть увагу жодн**ої** державніст**і** московською не пахне<br>\n",
    "зверніть увагу жодн**ої** державніст**і** московською не пахне<br>\n",
    "Here, the endings of three words are incorrect (wrong case), and the beam search made the right agreement only in the third word (the mistake persists in the first two though).<br>\n",
    "\n",
    "між частинами озброєним рушницями виблискували на сонці косарі **і** відділи озброєні косами<br>\n",
    "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами<br>\n",
    "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами<br>\n",
    "The beam search removed the conjunction 'i', which mistakenly appeared in the transcript.<br>\n",
    "\n",
    "рельє**в** хре**п**та сильно розчавлений **вусчьовій** зоні вирівнюється до пер**е**ферій за рахунок поховання **осить**<br>\n",
    "рельєф хребта сильно розчавлений в осьовій зоні вирівнюється до пер**е**ферій за рахунок поховання **осить**<br>\n",
    "рельєф хребта сильно розчавлений в осьовій зоні вирівнюється до пер**е**ферій за рахунок поховання **осить**<br>\n",
    "Here, the greedy search made multople mistakes -- and three of them were corrected by the beam search -- ranging from misspelled words (orthographic mistakes) to misheards.<br>\n",
    "\n",
    "### **Conclusion**\n",
    "Compared to the greedy search, the transcripts transcribed by the `CTCBeanSearchDecoder` are definitely of higher quality. Even if the corrections were minor for some sentences, e.g. separating the words that were previously glued together by the greedy search, they can be deemed considerable since in some cases these corrections were enough to restore the sentence meaning. In addition to that, the model clearly uses the extra linguistic knowledge provided by the LM -- most of the mistakes fixed by the beam search decoder pertained to mispelling the prefixes / roots of the words, or incorrect agreement in case, number, and gender between the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0e12d4-9927-4c4b-a9b0-74a160ada123",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Inference with `torchaudio`**\n",
    "Import the original `transformers` Wav2Vec2.0 pretrained weights and convert the model to `torchaudio`'s format. The model is built of three components:\n",
    "-  **feature_extractor** that extracts the acoustic features from the raw audio waveforms,\n",
    "-  **encoder** that converts the extracted features into a sequence of probability distribution (expressed in negative log-likelihood) over the expected labels, and\n",
    "-  **aux**, which is an auxiliary module; if specified, the encoder's output goes here. (In our case, it's the final projection layer of shape [in_features=1024, out_features=num_tokens.]\n",
    "The decoder is a standalone module in `torchaudio` that has to be instantiated separately from the three above. You can access and inspect the model's components as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2709a2ac-e482-48be-bd7e-95e80087d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchaudio.models.wav2vec2.model.Wav2Vec2Model'>\n",
      "Linear(in_features=1024, out_features=40, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model2 = import_huggingface_model(model1)\n",
    "print(model2.__class__)\n",
    "# print(model2.feature_extractor)\n",
    "# print(model2.encoder)\n",
    "print(model2.aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960046d3-53cc-48ee-80ff-93c79f58c875",
   "metadata": {},
   "source": [
    "### **Decoder**\n",
    "To be instantiated, the decoder requires loading the following data -- tokens (valid labels, i.e. letters + special symbols), lexicon (a dictionary of words and their spellings used to condition the model to only generate the words from this list), and a language model -- an N-gram model that contains probability scores expressed as logits for every known N-gram. Although this component is purely optional, using it signicantly boosts the decoding process and increases the transcription quality.\n",
    "\n",
    "#### Tokens\n",
    "These are a set of possible symbols that can be predicted by the ASR model, including letters of the alphabet, any other characters required by the orthographic rules of the language, and the blank and silent symbols. It can either be passed in as a file, where each line consists of the tokens corresponding to the same index, or as a list of tokens, each mapping to a unique index.<br>\n",
    "**OBS!** Since we're using a converted HuggingFace `Wav2Vec2` model, we can't use the default token values of the `torchaudio` `CTCDecoder` and have to modify these. According to the `torchaudio` documentation, the first two symbols in `tokens.txt` are usually the blank and silent character, and their default values are typically \"**-**\" (hyphen) and \"**|**\" (vertical bar) respectively. In `transformers`, in the original `Wab2Vec2` `CTCTokenizer` implementation, \"|\" is used as a word delimiter whereas \"[PAD]\" is a pad and a blank token that serves as a space between the letters within a single word. The blank token in `torchaudio` is configurable. Since Ukrainian spelling makes use of the \"**-**\" (hyphen) and \"**'**\" (apostrophe) symbols, we have to assign our `tokens.txt` and assign the \"[PAD]\" as a new value for the blank character. __You can't add, delete, or move the tokens around your file / list because all the symbols appear there in a fixed order. Therefore, changing it will break the original mapping from each token to its respective index and, as a consequence, ruin the decoding.__\n",
    "\n",
    "#### Lexicon\n",
    "The lexicon is a mapping from words to their corresponding tokens sequence, and is used to restrict the search space of the decoder to only words from the lexicon. The expected format of the lexicon file is a line per word, with a word followed by its space-split tokens. Conventionally, a word is separated from its sequence of tokens by a tab or a space.<br>\n",
    "The lexicon can be automatically generated from the `unigrams.txt` but you have to thoroughly inspect it and remove any lines that doesn't constitute a valid word. Otherwise, initialzing the decoder will throw an error. \n",
    "\n",
    "#### Language Model\n",
    "A language model can be used in decoding to improve the results, by factoring in a language model score that represents the likelihood of the sequence into the beam search computation.<br>\n",
    "**No Language Model**: To create a decoder instance without a language model, set `lm=None` when initializing the decoder.<br>\n",
    "**KenLM**: This is an n-gram language model trained with the KenLM library. Both the `.arpa` or the binarized `.bin` LM can be used, but the binary format is recommended for faster loading.\n",
    "\n",
    "The most important parameters to consider when initializing the beam-search CTC decoder are listed below. These can significantly impact the decoder's performance, so choosing their values can be a delicate process. Since all improvements come at their own cost, configuring these parameters will largely depend on the sacrifices you're ready to make in order to achieve the set goals, i.e. generating higher-quality transcriptions will definitely use more computational resources, so it will also take longer time to decode the model's outputs.\n",
    "\n",
    "#### `nbest`\n",
    "This parameter indicates the number of best hypotheses to return as well as their final logit scores, which is often beneficial while configuring the most optimal values for the inference. For instance, by setting `nbest=5` when building the beam search decoder, you'll be able to access the hypotheses with the top 5 scores.\n",
    "\n",
    "```python\n",
    "for i in range(5):\n",
    "    transcript = \" \".join(beam_search_result[0][i].words).strip()\n",
    "    score = beam_search_result[0][i].score\n",
    "```\n",
    "\n",
    "#### `beam size`\n",
    "This parameter determines the maximum number of best hypotheses to hold after each decoding step. Using larger beam sizes allows for exploring a larger range of possible hypotheses which can produce hypotheses with higher scores, but it's computationally more expensive and does not provide additional gains beyond a certain point (often, using a beam size of 1500 provides the same output as a beam size of 200).\n",
    "\n",
    "```python\n",
    "beam_sizes = [50, 200, 500, 1500]\n",
    "\n",
    "for beam_size in beam_sizes:\n",
    "    beam_search_decoder = ctc_decoder(\n",
    "        lexicon='lexicon.txt',\n",
    "        tokens='tokens.txt',\n",
    "        lm='5gram.arpa',\n",
    "        beam_size=beam_size,\n",
    "        lm_weight=LM_WEIGHT,\n",
    "        word_score=WORD_SCORE,\n",
    "    )\n",
    "\n",
    "    print_decoded(beam_search_decoder, emission, \"beam size\", beam_size)\n",
    "```\n",
    "\n",
    "#### `beam size token`\n",
    "This parameter corresponds to the number of tokens to consider for expanding each hypothesis at the decoding step. Exploring a larger number of next possible tokens increases the range of potential hypotheses, but yet again at the cost of computation.\n",
    "\n",
    "```python\n",
    "num_tokens = len(tokens)\n",
    "beam_size_tokens = [1, 5, 10, num_tokens]\n",
    "\n",
    "for beam_size_token in beam_size_tokens:\n",
    "    beam_search_decoder = ctc_decoder(\n",
    "        lexicon='lexicon.txt',\n",
    "        tokens='tokens.txt',\n",
    "        lm='5gram.arpa',\n",
    "        beam_size_token=beam_size_token,\n",
    "        lm_weight=LM_WEIGHT,\n",
    "        word_score=WORD_SCORE,\n",
    "    )\n",
    "\n",
    "    print_decoded(beam_search_decoder, emission, \"beam size token\", beam_size_token)\n",
    "```\n",
    "\n",
    "#### `beam threshold`\n",
    "This parameter is used to prune the stored hypotheses set at each decoding step, removing hypotheses whose scores are greater than `beam_threshold` away from the highest scoring hypothesis. There's a balance between choosing smaller thresholds to prune more hypotheses and reduce the search space, and choosing a large enough threshold such that plausible hypotheses are not pruned.\n",
    "\n",
    "```python\n",
    "beam_thresholds = [1, 5, 10, 25]\n",
    "\n",
    "for beam_threshold in beam_thresholds:\n",
    "    beam_search_decoder = ctc_decoder(\n",
    "        lexicon='lexicon.txt',\n",
    "        tokens='tokens.txt',\n",
    "        lm='5gram.arpa',\n",
    "        beam_threshold=beam_threshold,\n",
    "        lm_weight=LM_WEIGHT,\n",
    "        word_score=WORD_SCORE,\n",
    "    )\n",
    "\n",
    "    print_decoded(beam_search_decoder, emission, \"beam threshold\", beam_threshold)\n",
    "```\n",
    "\n",
    "#### `language model weight`\n",
    "This parameter is the weight to assign to the LM score which to accumulate with the ASR model score for determining the overall scores. Larger weights encourage the model to predict next words based on the language model, while smaller weights give more weight to the acoustic model score instead.\n",
    "\n",
    "```python\n",
    "lm_weights = [0, 5, 10]\n",
    "\n",
    "for lm_weight in lm_weights:\n",
    "    beam_search_decoder = ctc_decoder(\n",
    "        lexicon='lexicon.txt',\n",
    "        tokens='tokens.txt',\n",
    "        lm='5gram.arpa',\n",
    "        lm_weight=lm_weight,\n",
    "        word_score=WORD_SCORE,\n",
    "    )\n",
    "\n",
    "    print_decoded(beam_search_decoder, emission, \"lm weight\", lm_weight)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed604ba8-2445-4b93-a63a-e50d0b30f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the `tokens.txt` file\n",
    "# with open('tokens.txt', mode='w', encoding='utf-8') as f:\n",
    "#     for label in labels:\n",
    "#         f.write(\"{}\\n\".format(label))\n",
    "\n",
    "# Create the `lexicon.txt` file\n",
    "# with open('unigrams.txt', mode='r', encoding='utf-8') as f1:\n",
    "#     with open('lexicon.txt', mode='w', encoding='utf-8') as f2:\n",
    "#         for word in f1:\n",
    "#             word = word.strip()\n",
    "#             spacesplit_word = ' '.join(word)\n",
    "#             f2.write(\"{0}\\t{1} |\\n\".format(word, spacesplit_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef71e70-fb36-4fd6-8262-cc0be126ea70",
   "metadata": {},
   "source": [
    "### **Greedy Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45dc44a-86b7-40b3-b27a-cfceebe1d99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreedyCTCDecoder()\n",
      "[\"'\", '-', '[PAD]', '[UNK]', '|', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ь', 'ю', 'я', 'є', 'і', 'ї', 'ґ', '<s>', '</s>']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "class GreedyCTCDecoder(torch.nn.Module):\n",
    "    def __init__(self, labels, blank=0):\n",
    "        super().__init__()\n",
    "        self.labels = labels\n",
    "        self.blank = blank\n",
    "\n",
    "    def forward(self, emission):\n",
    "        indices = torch.argmax(emission, dim=-1)\n",
    "        indices = torch.unique_consecutive(indices, dim=-1).squeeze().tolist()\n",
    "        sequence = \"\".join([self.labels[i] for i in indices]).replace(\"[PAD]\", \"\")\n",
    "        # .replace(\"|\", \" \")\n",
    "        return sequence\n",
    "\n",
    "greedy_decoder = GreedyCTCDecoder(labels)\n",
    "print(greedy_decoder)\n",
    "print(labels)\n",
    "print(greedy_decoder.blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49bfcb92-3820-4cf7-a731-fa4a31dd2438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the greedy search decoding.\n",
      "про це повідомляє през служба поліції київської області \n",
      "зібрані дані застосовувалися поперше для гернерування адресної розсилки\n",
      "хто розмягається ог ворогого ко трого темля віно не томітили \n",
      "буває професійні помічники домовляються з дом о власником напавноційну за квартиру \n",
      "перестаралася з корекцію вилиць \n",
      "процесвічить її зваложена й доглянута шкіра\n",
      "сім'ї зінвалідими іншим пільговиками постійно потребуватимуть комплексної державної підтримки\n",
      "антибіотикорезистентний\n",
      "антианемічний\n",
      "до переваг цього методу належить простота технологічних схем і можливість творення замкнутих циклів\n",
      "еж сіймач вигра і захистив титул\n",
      "зверніть увагу жодної державністі московської не пахне\n",
      "між частинами озброєними рушницями ви блискували на сонці косарі відділи озброєні косари \n",
      "рельєф хрепта сильно розчавлений всовій зоні вирівнюється до переперіг за рахунок поховання осодь \n"
     ]
    }
   ],
   "source": [
    "# GREEDY SEARCH DECODING\n",
    "print(\"Test the greedy search decoding.\")\n",
    "transcriptons_greedy = []\n",
    "for wav_file in wav_files:\n",
    "    waveform, sample_rate = torchaudio.load(wav_file)\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000, resampling_method='sinc_interpolation')\n",
    "    features = resampler(waveform)\n",
    "    with torch.inference_mode():\n",
    "        emissions, _ = model2(features)\n",
    "        # Normalizing the model's output\n",
    "        emissions = torch.log_softmax(emissions, dim=-1).cpu().detach()\n",
    "        predicted_ids = greedy_decoder(emissions[0])\n",
    "        sequence= \"\".join(predicted_ids).replace(\"|\", \" \")\n",
    "        transcriptions_greedy.append(sequence)\n",
    "        print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c70388-dddb-4d81-8c7f-48f1aaed5cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading 5gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchaudio.models.decoder._ctc_decoder.CTCDecoder object at 0x7f3fef82e550>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "beam_search_decoder = ctc_decoder(\n",
    "    lexicon='lexicon.txt',\n",
    "    tokens='tokens.txt',\n",
    "    lm=\"5gram.arpa\",\n",
    "    nbest=3,\n",
    "    beam_size=200,\n",
    "    lm_weight=3.5,\n",
    "    word_score=-0.3,\n",
    "    blank_token = \"[PAD]\",\n",
    "    sil_token = \"|\",\n",
    "    unk_word = \"[UNK]\",\n",
    ")\n",
    "print(beam_search_decoder)\n",
    "# Check whether the decoder's blank character was set properly:\n",
    "# index = 2 is the \"[PAD]\" tokem, as required.\n",
    "print(beam_search_decoder.blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1331023f-661e-4433-ac4b-2c10e1e14931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the beam search decoding.\n",
      "про це повідомляє прес-служба поліції київської області\n",
      "зібране дані застосовуватися по-перше для переривання адресою носилки\n",
      "хто розлягається ворожого котрого в темряві мене помітили\n",
      "буває професійні помічники домовляються з домовласником на певну ціну за квартиру\n",
      "перестаралася з корекцією вилиць\n",
      "про це свідчить її зволожена й доглянута шкіра\n",
      "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки\n",
      "антибіотикорезистентний\n",
      "антианемічний\n",
      "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів\n",
      "піймав виграв і захистив титул\n",
      "зверніть увагу жодною державністю московською не пахне\n",
      "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами\n",
      "рельєф хребта сильно розчавленій свій зоні вирівнюється до периферії за рахунок поховання осадів\n"
     ]
    }
   ],
   "source": [
    "# BEAM SEARCH DECODING\n",
    "print(\"Test the beam search decoding.\")\n",
    "transcriptions_beam = []\n",
    "for wav_file in wav_files:\n",
    "    waveform, sample_rate = torchaudio.load(wav_file)\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000, resampling_method='sinc_interpolation')\n",
    "    speech = resampler(waveform)\n",
    "    with torch.inference_mode():\n",
    "        emissions, _ = model2(speech)\n",
    "        # Normalizing the model's output\n",
    "        emissions = torch.log_softmax(emissions, dim=-1)\n",
    "        sequence = beam_search_decoder(emissions.cpu().detach())\n",
    "        sequence = \" \".join(sequence[0][0].words).strip()\n",
    "        transcriptions_beam.append(sequence)\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf08bd-a858-4102-9180-7ec9fdd9c0d6",
   "metadata": {},
   "source": [
    "### **Error Analysis**\n",
    "\n",
    "OBS! For each audio file, Line 1 -- greedy search, Line 2 -- beam search (`beam_size=200`), Line 3 -- beam search (`beam_size=500`), Line 4 -- beam search (beam_size=1500). Mistakes are marked in bold.\n",
    "\n",
    "про це повідомляє пре**з**служба поліції київської області<br>\n",
    "про це повідомляє прес-служба поліції київської області<br>\n",
    "про це повідомляє прес-служба поліції київської області<br>\n",
    "про це повідомляє прес-служба поліції київської області<br>\n",
    "With as few as 200 beams, the beam search decoding allowed to fix the mistakes -- find a correct root consonant for the word 'прес' (press) and add a hyphen between the words 'прес' and 'служба' (service). (The default value of the number of beams to utilize is 50.)<br>\n",
    "\n",
    "зібрані дані застосовувалися **поперше** для ге**р**нерування адресної розсилки<br>\n",
    "зібран**е** дані застосовуватися по-перше для **мене вання** адрес**ою** **но**силки<br>\n",
    "зібран**е** дані застосовуватися по-перше для **переривання** **адресою** **носилки**<br>\n",
    "зібран**е** дані застосовуватися по-перше для **переривання** **адресою** **носилки**<br>\n",
    "This sample is a sad example of how the beam search can go rogue -- it made mistakes in every word, except words #4 and #5. The errors in the last 3 words are especially grave because the generated words aren't even close to the reference transcript. However, the LM seems to be working perfectly fine -- we no longer have the issues with the words that should be hyphened, e.g. 'по-перше' (firstly).<br>\n",
    "\n",
    "хто розлягаєтьця **ог** в**о**ртового **ктрого** **втемля** **віноне** помітили<br>\n",
    "хто розлягається **ворожого** котрого в темряві **ме**не помітили<br>\n",
    "хто розлягається **готового** котрого в темряві **не** не помітили<br>\n",
    "хто розлягається **готового** котрого в темряві **ме**не помітили<br>\n",
    "Unfortunately, the beam search decoder didn't achieve much in this sentence either (still issues with the word #3: 'готового' should be 'гук вартового', and the word #7: 'мене' should be 'ми не'.<br>\n",
    " \n",
    "буває професійні помічники домовляються **здом** **о**власником на п**а**вну ціну за квартиру<br> \n",
    "буває професійні помічники домовляються з домовласником на певну ціну за квартиру<br>\n",
    "буває професійні помічники домовляються з домовласником на певну ціну за квартиру<br>\n",
    "буває професійні помічники домовляються з домовласником на певну ціну за квартиру<br>\n",
    "Here, the beam search decoder fixed the transcription mistakes made by the greedy search decoder using just 200 paths, again.<br>\n",
    "\n",
    "перестаралася з корекці**ю** вилиць<br>\n",
    "перестаралася з корекцією вилиць<br>\n",
    "перестаралася з корекцією вилиць<br>\n",
    "перестаралася з корекцією вилиць<br>\n",
    "The greedy search transcribed an incorrect case ending for the word #3 'корекцію' (correction; a term used in plastic surgery), and the beam search corrected it.<br>\n",
    "\n",
    "**проц**е **свічить** її зв**а**ложена й доглянута шкіра<br>\n",
    "про це свідчить її зволожена й доглянута шкіра<br>\n",
    "про це свідчить її зволожена й доглянута шкіра<br>\n",
    "про це свідчить її зволожена й доглянута шкіра<br>\n",
    "Again, all the mistakes made by the greedy search were corrected by the beam search.<br>\n",
    "\n",
    "сім'ї **зінвалідами** іншим пільговиками постійно потребуватимуть комплексної державної підтримки<br>\n",
    "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки<br>\n",
    "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки<br>\n",
    "сім'ї з інвалідами іншими пільговиками постійно потребуватимуть комплексної державної підтримки<br>\n",
    "Everything is transcribed perfectly in this example.<br>\n",
    "\n",
    "антибіотикорезистентний<br>\n",
    "антибіотикорезистентний<br>\n",
    "антибіотикорезистентний<br>\n",
    "антибіотикорезистентний<br>\n",
    "Correct. (The word means 'antibiotic-resistant'.)<br>\n",
    "\n",
    "антианемічний<br>\n",
    "антианемічний<br>\n",
    "антианемічний<br>\n",
    "антианемічний<br>\n",
    "Correct. (The word means 'antianemic'.)<br>\n",
    "\n",
    "до переваг цього методу належить простота технологічних схем і можливість **творення** замкнутих циклів<br>\n",
    "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів<br>\n",
    "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів<br>\n",
    "до переваг цього методу належить простота технологічних схем і можливість створення замкнутих циклів<br>\n",
    "The beam search correctly added a prefix to the word #11 ('творення' -> 'створення').<br>\n",
    "\n",
    "**ечсвіймач вегра** і захистив титул<br>\n",
    "**сімей** виграв і захистив титул<br>\n",
    "едж свій матч виграв і захистив титул<br>\n",
    "едж свій матч виграв і захистив титул<br>\n",
    "This sentence was a big problem for the `transformers` beam search -- no amount of beams was enough to correctly transcribe the first 4 words ('едж свій матч виграв' reads 'Edge [surname] won his match'). The beam search provided via `torchaudio` finally achieves this goal with 500 beams.<br>\n",
    "\n",
    "зверніть увагу жодн**ої** державніст**і** московськ**ої** не пахне<br>\n",
    "зверніть увагу жодною державністю московською не пахне<br>\n",
    "зверніть увагу жодною державністю московською не пахне<br>\n",
    "зверніть увагу жодною державністю московською не пахне<br>\n",
    "The beam search algorithm corrects the case endings for the words #3, #4, and #5.<br>\n",
    "\n",
    "між частинами озброєни**м** рушницями **ви блискували** на сонці косарі відділи озброєні косари<br>\n",
    "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами<br>\n",
    "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами<br>\n",
    "між частинами озброєними рушницями виблискували на сонці косарі відділи озброєні косами<br>\n",
    "There are no orthographic mistakes in the transcriptions generated by the beam search but this sentence is a prime example of how the punctuation is essentially ignored by many ASR models: the last 3 words constitute a clarifying clause that describes the 4th word from the end in more details and, thus, should be separated from it by either a comma or a dash.<br>\n",
    "\n",
    "рельє**в** хре**п**та сильно розчавлений **в сьовій** зоні вирінюється до **переперіг** за р**о**хунок поховання **осоді**<br>\n",
    "рельєф хребта сильно розчавленій свій зоні вирівнюється до периферії за рахунок поховання осадів<br>\n",
    "рельєф хребта сильно розчавленій **о**сьовій зоні вирівнюється до периферії за рахунок поховання осадів<br>\n",
    "рельєф хребта сильно розчавленій **о**сьовій зоні вирівнюється до периферії за рахунок поховання осадів<br>\n",
    "In the final example, the beam search algorithm brilliantly fixes all the spelling mistakes. One of them persistently remained a problem for the `transformers` beam search -- it kept spelling 'переферії' instead of the correct 'периферії', even after attaching 2 different LMs to it. However, the `torchaudio` beam search powered by the LM solved the issue. The only mistake made by the beam search here is the omitted preposition between the words #4 and #5 (it's difficult to predict whether the NMT model is sensitive to that or not.)<br>\n",
    "\n",
    "### **Conclusion**\n",
    "Although after using the `torchaudio` beam search decoder, there still are transcribing errors left in some sentences, my overall judgement is that it presented itself as a robust and reliable tool. Using it is certainly beneficial for the ASR task, and the ASR model performs especially well when boosted by the external linguistic data (mainly, the spelling dictionary and the language model). At certain points, the `torchaudio` beam-search CTC decoder outperformed its competitor, the `transformers` beam-search CTC decoder, which indicates that we should consider it as the primary CTC decoder for any our future ASR work, in case we choose to utilize the beam search algorithm in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de965a5a-34b6-470b-a014-6fd6bbb1d693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
